import discord
from discord.ext import commands
from discord import app_commands
from typing import Optional, List, Dict, Tuple, Any, Union, AsyncGenerator
import logging
import re
import pytz
import uuid
from functools import lru_cache
from config.settings import settings
from utils.helpers import truncate_text
from utils.pagination import MultiEmbedPaginationView
from utils.embed_helper import DiscordEmbedBuilder
from utils.attachment_helper import AttachmentProcessor
from utils.thread_stats import get_thread_stats
from utils.cache_manager import cache_manager
from utils.error_handler import handle_command_errors
import asyncio
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from utils.search_query_parser import SearchQueryParser

logger = logging.getLogger('discord_bot.search')



class Search(commands.Cog, name="search"):
    def __init__(self, bot: commands.Bot) -> None:
        self.bot: commands.Bot = bot
        self.embed_builder: DiscordEmbedBuilder = DiscordEmbedBuilder(settings.bot.embed_color)
        self.attachment_processor: AttachmentProcessor = AttachmentProcessor()
        self._logger: logging.Logger = logger
        self._logger.info("Search cog initialized")

        # Use unified cache manager
        self._thread_cache = cache_manager.thread_cache

        # Active searches tracking for cancellation
        self._active_searches: Dict[str, Dict[str, Any]] = {}

        # User search history
        self._search_history: Dict[int, List[Dict[str, Any]]] = {}

        # æ·»åŠ æŸ¥è¯¢è§£æå™¨
        self._query_parser: SearchQueryParser = SearchQueryParser()

        # Concurrency control with dynamic adjustment
        self._max_concurrency: int = settings.search.concurrent_limit
        self._search_semaphore: asyncio.Semaphore = asyncio.Semaphore(self._max_concurrency)

        # Compile common regex patterns
        self._url_pattern: re.Pattern[str] = re.compile(r'https?://\S+')

        # Sorting functions mapping
        self._sort_functions: Dict[str, Tuple[Callable[[Dict[str, Any]], Any], bool]] = {
            "æœ€é«˜ååº”é™åº": (lambda x: x['stats']['reaction_count'], True),
            "æœ€é«˜ååº”å‡åº": (lambda x: x['stats']['reaction_count'], False),
            "æ€»å›å¤æ•°é™åº": (lambda x: x['stats']['reply_count'], True),
            "æ€»å›å¤æ•°å‡åº": (lambda x: x['stats']['reply_count'], False),
            "å‘å¸–æ—¶é—´ç”±æ–°åˆ°æ—§": (lambda x: x['thread'].created_at, True),
            "å‘å¸–æ—¶é—´ç”±æ—§åˆ°æ–°": (lambda x: x['thread'].created_at, False),
            "æœ€åæ´»è·ƒç”±æ–°åˆ°æ—§": (lambda x: x['thread'].last_message.created_at if x['thread'].last_message else x['thread'].created_at, True),
            "æœ€åæ´»è·ƒç”±æ—§åˆ°æ–°": (lambda x: x['thread'].last_message.created_at if x['thread'].last_message else x['thread'].created_at, False)
        }

        # Background tasks - only search cleanup since cache is managed globally
        self._search_cleanup_task: asyncio.Task[None] = bot.loop.create_task(self._cleanup_searches_task())

    async def cog_unload(self) -> None:
        """Clean up when cog is unloaded"""
        if self._search_cleanup_task:
            self._search_cleanup_task.cancel()

    async def _cleanup_searches_task(self) -> None:
        """Clean up old searches"""
        while not self.bot.is_closed():
            try:
                current_time = datetime.now()
                expired_searches = []

                # Find searches older than 10 minutes
                for search_id, search_info in self._active_searches.items():
                    if (current_time - search_info["start_time"]).total_seconds() > 600:
                        expired_searches.append(search_id)

                # Remove expired searches
                for search_id in expired_searches:
                    if search_id in self._active_searches:
                        del self._active_searches[search_id]

                if expired_searches:
                    self._logger.debug(f"Search cleanup: removed {len(expired_searches)} expired searches")
            except Exception as e:
                self._logger.error(f"Error in search cleanup: {e}")
            await asyncio.sleep(300)  # Run every 5 minutes

    @lru_cache(maxsize=256)
    def _check_tags(self, thread_tags: Tuple[str], search_tags: Tuple[str], exclude_tags: Tuple[str]) -> bool:
        """Check if thread tags match search conditions (with caching)"""
        thread_tags_lower = tuple(tag.lower() for tag in thread_tags)

        # Check if search tags match (any required tag must be present)
        if search_tags and not any(tag in thread_tags_lower for tag in search_tags):
            return False

        # Check if any excluded tag is present
        if exclude_tags and any(tag in thread_tags_lower for tag in exclude_tags):
            return False

        return True

    def _preprocess_keywords(self, keywords: List[str]) -> List[str]:
        """Preprocess search keywords for better matching"""
        if not keywords:
            return []

        # Clean and normalize keywords
        processed = []
        for keyword in keywords:
            if not keyword or not keyword.strip():
                continue
            # Convert to lowercase and strip whitespace
            cleaned = keyword.strip().lower()
            if cleaned:
                processed.append(cleaned)

        return processed

    def _check_keywords(self, content: str, search_query: str, exclude_keywords: List[str]) -> bool:
        """ä½¿ç”¨é«˜çº§æœç´¢è¯­æ³•æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ¹é…"""
        if not content:
            return not search_query

        content_lower = content.lower()

        # å…ˆæ£€æŸ¥æ’é™¤å…³é”®è¯
        if exclude_keywords and any(keyword in content_lower for keyword in exclude_keywords):
            return False

        # å¦‚æœæ²¡æœ‰æœç´¢æŸ¥è¯¢ï¼Œåˆ™åŒ¹é…æˆåŠŸ
        if not search_query:
            return True

        # è§£æå¹¶è¯„ä¼°æœç´¢æŸ¥è¯¢
        query_tree = self._query_parser.parse_query(search_query)

        # ç®€å•æŸ¥è¯¢ä½¿ç”¨ç°æœ‰é€»è¾‘
        if query_tree["type"] == "simple":
            return all(keyword in content_lower for keyword in query_tree["keywords"])

        # é«˜çº§æŸ¥è¯¢ä½¿ç”¨è¯­æ³•æ ‘è¯„ä¼°
        if query_tree["type"] == "advanced":
            return self._query_parser.evaluate(query_tree["tree"], content)

        # ç©ºæŸ¥è¯¢å§‹ç»ˆåŒ¹é…
        if query_tree["type"] == "empty":
            return True

        # æœªçŸ¥æŸ¥è¯¢ç±»å‹
        self._logger.warning(f"æœªçŸ¥æŸ¥è¯¢ç±»å‹: {query_tree['type']}")
        return False

    async def _process_single_thread(self, thread: discord.Thread, conditions: Dict[str, Any],
                                    cancel_event: Optional[asyncio.Event] = None) -> Optional[Dict[str, Any]]:
        """Process a single thread for search (optimized version)"""
        try:
            # Check cancellation
            if cancel_event and cancel_event.is_set():
                return None

            async with self._search_semaphore:
                # Quick validation
                if not thread or not thread.id:
                    return None

                # First check date range (if specified)
                if conditions.get('start_date') and thread.created_at < conditions['start_date']:
                    return None

                if conditions.get('end_date') and thread.created_at > conditions['end_date']:
                    return None

                # Then check author conditions (cheap operation)
                if conditions['original_poster'] and thread.owner and thread.owner.id != conditions['original_poster'].id:
                    return None

                if conditions['exclude_op'] and thread.owner and thread.owner.id == conditions['exclude_op'].id:
                    return None

                # Check tags (cached function for efficiency)
                thread_tag_names = tuple(tag.name for tag in thread.applied_tags)
                search_tags = tuple(conditions.get('search_tags', []))
                exclude_tags = tuple(conditions.get('exclude_tags', []))

                if not self._check_tags(thread_tag_names, search_tags, exclude_tags):
                    return None

                # If we've passed all the above checks, now fetch the first message
                first_message = None
                retry_count = 0
                max_retries = 2

                while retry_count <= max_retries:
                    try:
                        # Check cancellation again
                        if cancel_event and cancel_event.is_set():
                            return None

                        # Fetch first message
                        first_message = await thread.fetch_message(thread.id)
                        break
                    except discord.NotFound:
                        return None
                    except discord.HTTPException as e:
                        if e.status == 429:  # Rate limited
                            retry_after = e.retry_after or (1 * (retry_count + 1))
                            self._logger.warning(f"Rate limited, waiting {retry_after}s")
                            await asyncio.sleep(retry_after)
                            retry_count += 1
                        elif 500 <= e.status < 600:  # Server error, retry
                            await asyncio.sleep(1 * (retry_count + 1))
                            retry_count += 1
                        else:
                            self._logger.warning(f"Failed to get first message for thread {thread.id}: {e}")
                            return None
                    except Exception as e:
                        self._logger.warning(f"Error fetching message for thread {thread.id}: {e}")
                        return None

                if not first_message:
                    return None

                # Check content keywords
                if first_message.content:
                    # Efficiently check keywords
                    if not self._check_keywords(
                        first_message.content,
                        conditions.get('search_query', ''),
                        conditions.get('exclude_keywords', [])
                    ):
                        return None
                elif conditions.get('search_query'):
                    # If there are search keywords but no content, it's a mismatch
                    return None

                # Get thread statistics
                try:
                    # Check cancellation
                    if cancel_event and cancel_event.is_set():
                        return None

                    # Get thread stats using the new cache system
                    cached_stats = await self._thread_cache.get_thread_stats(str(thread.id))
                    if cached_stats:
                        stats = cached_stats
                    else:
                        # Fetch fresh stats and cache them
                        stats = await get_thread_stats(thread)
                        await self._thread_cache.set_thread_stats(str(thread.id), stats)

                    # Additional numeric filters
                    if conditions.get('min_reactions') is not None and stats.get('reaction_count', 0) < conditions['min_reactions']:
                        return None

                    if conditions.get('min_replies') is not None and stats.get('reply_count', 0) < conditions['min_replies']:
                        return None

                except Exception as e:
                    self._logger.error(f"Error getting stats for thread {thread.id}: {e}")
                    stats = {'reaction_count': 0, 'reply_count': 0}

                # All checks passed, return the result
                return {
                    'thread': thread,
                    'stats': stats,
                    'first_message': first_message
                }

        except asyncio.CancelledError:
            raise
        except Exception as e:
            thread_name = getattr(thread, 'name', 'unknown')
            thread_id = getattr(thread, 'id', 'unknown')
            self._logger.error(f"Error processing thread {thread_name} ({thread_id}): {e}", exc_info=True)
            return None

    async def _process_thread_batch(self, threads: List[discord.Thread], search_conditions: Dict[str, Any],
                                   cancel_event: Optional[asyncio.Event] = None) -> List[Dict[str, Any]]:
        """Process a batch of threads with smart concurrency control"""
        if not threads:
            return []

        # For small batches, process sequentially to avoid overhead
        if len(threads) <= 3:
            results = []
            for thread in threads:
                if cancel_event and cancel_event.is_set():
                    break
                result = await self._process_single_thread(thread, search_conditions, cancel_event)
                if result:
                    results.append(result)
            return results

        # For larger batches, process concurrently
        tasks = []
        for thread in threads:
            if cancel_event and cancel_event.is_set():
                break

            task = asyncio.create_task(
                self._process_single_thread(thread, search_conditions, cancel_event)
            )
            tasks.append(task)

        if not tasks:
            return []

        # Gather results, ignoring exceptions
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return [r for r in results if r is not None and not isinstance(r, Exception)]

    async def _search_archived_threads(self, forum_channel, search_conditions, progress_message,
                                      search_id, max_results=1000, total_active=0):
        """Search archived threads with progress updates and cancellation support"""
        filtered_results = []
        processed_count = total_active
        batch_size = 100  # Discord API limit
        batch_count = 0
        last_thread = None
        error_count = 0
        cancel_event = self._active_searches.get(search_id, {}).get("cancel_event")

        start_time = datetime.now()
        last_update_time = start_time

        while True:
            # Check cancellation
            if cancel_event and cancel_event.is_set():
                await progress_message.edit(
                    embed=self.embed_builder.create_warning_embed(
                        "æœç´¢å·²å–æ¶ˆ",
                        f"âœ“ å·²å¤„ç†: {processed_count} ä¸ªå¸–å­\n"
                        f"ğŸ“Š åŒ¹é…ç»“æœ: {len(filtered_results)} ä¸ª\n"
                        f"â±ï¸ ç”¨æ—¶: {(datetime.now() - start_time).total_seconds():.1f} ç§’"
                    )
                )
                return filtered_results

            # Stop if we reached the maximum results
            if len(filtered_results) >= max_results:
                await progress_message.edit(
                    embed=self.embed_builder.create_info_embed(
                        "æœç´¢è¶…å‡ºä¸Šé™",
                        f"ğŸ” å·²è¾¾åˆ°æœ€å¤§ç»“æœæ•° ({max_results})\n"
                        f"âœ“ å·²å¤„ç†: {processed_count} ä¸ªå¸–å­\n"
                        f"â±ï¸ ç”¨æ—¶: {(datetime.now() - start_time).total_seconds():.1f} ç§’"
                    )
                )
                return filtered_results

            try:
                # Fetch a batch of archived threads
                archived_threads = []
                async for thread in forum_channel.archived_threads(limit=batch_size, before=last_thread):
                    archived_threads.append(thread)
                    last_thread = thread

                if not archived_threads:
                    break  # No more threads to process

                batch_count += 1

                # Process this batch
                batch_results = await self._process_thread_batch(
                    archived_threads, search_conditions, cancel_event
                )

                if batch_results:
                    filtered_results.extend(batch_results)

                processed_count += len(archived_threads)
                current_time = datetime.now()
                elapsed_time = (current_time - start_time).total_seconds()

                # Update progress message (not too frequently to avoid rate limits)
                if (current_time - last_update_time).total_seconds() >= 1.5:
                    await progress_message.edit(
                        embed=self.embed_builder.create_info_embed(
                            "æœç´¢è¿›è¡Œä¸­",
                            f"âœ“ å·²å¤„ç†: {processed_count} ä¸ªå¸–å­\n"
                            f"ğŸ“Š åŒ¹é…ç»“æœ: {len(filtered_results)} ä¸ª\n"
                            f"â±ï¸ ç”¨æ—¶: {elapsed_time:.1f} ç§’\n"
                            f"ğŸ“¦ å·²å¤„ç† {batch_count} æ‰¹å­˜æ¡£å¸–å­"
                        )
                    )
                    last_update_time = current_time

            except asyncio.CancelledError:
                raise
            except Exception as e:
                error_count += 1
                self._logger.error(f"Error retrieving archived threads: {e}")

                # Update with error info
                current_time = datetime.now()
                if (current_time - last_update_time).total_seconds() >= 2:
                    await progress_message.edit(
                        embed=self.embed_builder.create_warning_embed(
                            "æœç´¢è¿›è¡Œä¸­",
                            f"âŒ æ‰¹æ¬¡ {batch_count} å‡ºç°é”™è¯¯\n"
                            f"âœ“ å·²å¤„ç†: {processed_count} ä¸ªå¸–å­\n"
                            f"ğŸ“Š å½“å‰ç»“æœ: {len(filtered_results)} ä¸ª\n"
                            f"â³ å°è¯•ç»§ç»­æœç´¢..."
                        )
                    )
                    last_update_time = current_time

                if error_count >= 3:  # Stop after too many consecutive errors
                    break

                # Add delay before retry
                await asyncio.sleep(2)

        return filtered_results

    def _parse_date(self, date_str: str) -> Optional[datetime]:
        """Parse date string with multiple formats support"""
        if not date_str:
            return None

        # Try various date formats
        formats = [
            "%Y-%m-%d",  # 2023-01-15
            "%Y/%m/%d",  # 2023/01/15
            "%m/%d/%Y",  # 01/15/2023
            "%d.%m.%Y"   # 15.01.2023
        ]

        # Try each format
        for fmt in formats:
            try:
                return datetime.strptime(date_str, fmt)
            except ValueError:
                continue

        # Try relative date expressions like "7d" (7 days), "3m" (3 months), etc.
        match = re.match(r'^(\d+)([dmyw])$', date_str.lower())
        if match:
            num, unit = match.groups()
            num = int(num)
            now = datetime.now()

            if unit == 'd':  # days
                return now - timedelta(days=num)
            elif unit == 'w':  # weeks
                return now - timedelta(weeks=num)
            elif unit == 'm':  # months (approximate)
                return now - timedelta(days=num*30)
            elif unit == 'y':  # years (approximate)
                return now - timedelta(days=num*365)

        return None

    def _store_search_history(self, user_id: int, search_info: Dict) -> None:
        """Store search in user history"""
        if user_id not in self._search_history:
            self._search_history[user_id] = []

        # Add current search
        self._search_history[user_id].insert(0, {
            **search_info,
            'timestamp': datetime.now()
        })

        # Keep only recent searches
        self._search_history[user_id] = self._search_history[user_id][:10]

    @app_commands.command(name="search_syntax", description="æ˜¾ç¤ºé«˜çº§æœç´¢è¯­æ³•è¯´æ˜")
    @app_commands.guild_only()
    @handle_command_errors()
    async def search_syntax(self, interaction: discord.Interaction):
        """æ˜¾ç¤ºé«˜çº§æœç´¢è¯­æ³•å¸®åŠ©"""
        embed = discord.Embed(
            title="é«˜çº§æœç´¢è¯­æ³•æŒ‡å—",
            description="è®ºå›æœç´¢æ”¯æŒä»¥ä¸‹é«˜çº§è¯­æ³•åŠŸèƒ½ï¼š",
            color=settings.bot.embed_color
        )

        embed.add_field(
            name="åŸºæœ¬å…³é”®è¯",
            value="è¾“å…¥å¤šä¸ªå…³é”®è¯ä¼šåŒ¹é…åŒæ—¶åŒ…å«æ‰€æœ‰å…³é”®è¯çš„å¸–å­ï¼ˆANDé€»è¾‘ï¼‰\n"
                  "ä¾‹å¦‚ï¼š`é—®é¢˜ è§£å†³æ–¹æ¡ˆ`",
            inline=False
        )

        embed.add_field(
            name="OR æ“ä½œç¬¦",
            value="ä½¿ç”¨ `OR` æˆ– `|` åŒ¹é…ä»»ä¸€å…³é”®è¯\n"
                  "ä¾‹å¦‚ï¼š`è§£å†³æ–¹æ¡ˆ OR æ›¿ä»£æ–¹æ³•`\n"
                  "ä¾‹å¦‚ï¼š`ä¸»é¢˜ | å†…å®¹ | æ ‡é¢˜`",
            inline=False
        )

        embed.add_field(
            name="NOT æ“ä½œç¬¦",
            value="ä½¿ç”¨ `NOT` æˆ– `-` æ’é™¤åŒ…å«æŸå…³é”®è¯çš„å¸–å­\n"
                  "ä¾‹å¦‚ï¼š`é—®é¢˜ NOT å·²è§£å†³`\n"
                  "ä¾‹å¦‚ï¼š`é—®é¢˜ -å·²è§£å†³`",
            inline=False
        )

        embed.add_field(
            name="ç²¾ç¡®çŸ­è¯­åŒ¹é…",
            value="ä½¿ç”¨å¼•å· `\"...\"` è¿›è¡Œç²¾ç¡®çŸ­è¯­åŒ¹é…\n"
                  "ä¾‹å¦‚ï¼š`\"å®Œæ•´çŸ­è¯­åŒ¹é…\"`",
            inline=False
        )

        embed.add_field(
            name="ç»„åˆä½¿ç”¨",
            value="å¯ä»¥ç»„åˆä½¿ç”¨å¤šç§æ“ä½œç¬¦\n"
                  "ä¾‹å¦‚ï¼š`(ä¸»é¢˜ | å†…å®¹) NOT \"å·²è§£å†³\"`",
            inline=False
        )

        await interaction.response.send_message(embed=embed, ephemeral=True)

    @app_commands.command(name="forum_search", description="æœç´¢è®ºå›å¸–å­")
    @app_commands.guild_only()
    @handle_command_errors()
    @app_commands.describe(
        forum_name="é€‰æ‹©è¦æœç´¢çš„è®ºå›åˆ†åŒº",
        order="ç»“æœæ’åºæ–¹å¼",
        original_poster="æŒ‡å®šçš„å‘å¸–äººï¼ˆé€‰æ‹©æˆå‘˜ï¼‰",
        tag1="é€‰æ‹©è¦æœç´¢çš„ç¬¬ä¸€ä¸ªæ ‡ç­¾",
        tag2="é€‰æ‹©è¦æœç´¢çš„ç¬¬äºŒä¸ªæ ‡ç­¾",
        tag3="é€‰æ‹©è¦æœç´¢çš„ç¬¬ä¸‰ä¸ªæ ‡ç­¾",
        search_word="æœç´¢å…³é”®è¯ï¼ˆæ”¯æŒé«˜çº§è¯­æ³•ï¼šOR, AND, NOT, \"ç²¾ç¡®çŸ­è¯­\"ï¼‰",
        exclude_word="æ’é™¤å…³é”®è¯ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰",
        exclude_op="æ’é™¤çš„ä½œè€…ï¼ˆé€‰æ‹©æˆå‘˜ï¼‰",
        exclude_tag1="é€‰æ‹©è¦æ’é™¤çš„ç¬¬ä¸€ä¸ªæ ‡ç­¾",
        exclude_tag2="é€‰æ‹©è¦æ’é™¤çš„ç¬¬äºŒä¸ªæ ‡ç­¾",
        start_date="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD æˆ– 7d è¡¨ç¤ºæœ€è¿‘7å¤©)",
        end_date="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)",
        min_reactions="æœ€ä½ååº”æ•°",
        min_replies="æœ€ä½å›å¤æ•°"
    )
    @app_commands.choices(order=[
        app_commands.Choice(name=option, value=option)
        for option in settings.search.search_order_options
    ])
    async def forum_search(
        self,
        interaction: discord.Interaction,
        forum_name: str,
        order: str = "æœ€é«˜ååº”é™åº",
        original_poster: Optional[discord.User] = None,
        tag1: Optional[str] = None,
        tag2: Optional[str] = None,
        tag3: Optional[str] = None,
        search_word: Optional[str] = None,
        exclude_word: Optional[str] = None,
        exclude_op: Optional[discord.User] = None,
        exclude_tag1: Optional[str] = None,
        exclude_tag2: Optional[str] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        min_reactions: Optional[int] = None,
        min_replies: Optional[int] = None
    ):
        """æœç´¢è®ºå›å¸–å­çš„å‘½ä»¤å®ç°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        try:
            self._logger.info(f"Search command invoked - User: {interaction.user}")

            # Permission check
            if not interaction.guild:
                await interaction.response.send_message(
                    embed=self.embed_builder.create_error_embed("å‘½ä»¤é”™è¯¯", "è¯¥å‘½ä»¤åªèƒ½åœ¨æœåŠ¡å™¨ä¸­ä½¿ç”¨"),
                    ephemeral=True
                )
                return

            permissions = interaction.channel.permissions_for(interaction.guild.me)
            if not (permissions.send_messages and permissions.embed_links):
                await interaction.response.send_message(
                    embed=self.embed_builder.create_error_embed("æƒé™é”™è¯¯", "Botç¼ºå°‘å¿…è¦æƒé™ï¼Œéœ€è¦ï¼šå‘é€æ¶ˆæ¯ã€åµŒå…¥é“¾æ¥æƒé™"),
                    ephemeral=True
                )
                return

            # Create search ID and setup cancellation tracking
            search_id = str(uuid.uuid4())
            cancel_event = asyncio.Event()
            self._active_searches[search_id] = {
                "cancel_event": cancel_event,
                "start_time": datetime.now()
            }

            # Defer response to give more processing time
            await interaction.response.defer(ephemeral=True)

            # Get forum channel
            forum_channel = interaction.guild.get_channel(int(forum_name))
            if not isinstance(forum_channel, discord.ForumChannel):
                await interaction.followup.send(
                    embed=self.embed_builder.create_error_embed("æœç´¢é”™è¯¯", "æœªæ‰¾åˆ°æŒ‡å®šçš„è®ºå›åˆ†åŒº"),
                    ephemeral=True
                )
                return

            # Parse date ranges if provided
            start_datetime = None
            end_datetime = None
            date_error = None

            if start_date:
                start_datetime = self._parse_date(start_date)
                if not start_datetime:
                    date_error = f"æ— æ³•è§£æå¼€å§‹æ—¥æœŸ: {start_date}"

            if end_date:
                end_datetime = self._parse_date(end_date)
                if not end_datetime:
                    date_error = f"æ— æ³•è§£æç»“æŸæ—¥æœŸ: {end_date}"
                else:
                    # Include the entire end date
                    end_datetime = end_datetime + timedelta(days=1, microseconds=-1)

            if date_error:
                await interaction.followup.send(
                    embed=self.embed_builder.create_error_embed("æ—¥æœŸæ ¼å¼é”™è¯¯", date_error + "\nè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼æˆ–ç›¸å¯¹æ—¥æœŸï¼ˆä¾‹å¦‚ 7d è¡¨ç¤ºæœ€è¿‘7å¤©ï¼‰"),
                    ephemeral=True
                )
                return

            # Preprocess search conditions
            search_conditions = {
                'search_tags': set(tag.lower() for tag in [tag1, tag2, tag3] if tag),
                'exclude_tags': set(tag.lower() for tag in [exclude_tag1, exclude_tag2] if tag),
                'search_query': search_word,
                'exclude_keywords': self._preprocess_keywords(exclude_word.split(",") if exclude_word else []),
                'original_poster': original_poster,
                'exclude_op': exclude_op,
                'start_date': start_datetime,
                'end_date': end_datetime,
                'min_reactions': min_reactions,
                'min_replies': min_replies
            }

            # Generate search condition summary
            condition_summary = []
            if search_conditions['search_tags']:
                condition_summary.append(f"ğŸ·ï¸ åŒ…å«æ ‡ç­¾: {', '.join(search_conditions['search_tags'])}")
            if search_conditions['exclude_tags']:
                condition_summary.append(f"ğŸš« æ’é™¤æ ‡ç­¾: {', '.join(search_conditions['exclude_tags'])}")
            if search_conditions['search_query']:
                condition_summary.append(f"ğŸ” å…³é”®è¯: {search_conditions['search_query']}")
            if search_conditions['exclude_keywords']:
                condition_summary.append(f"âŒ æ’é™¤è¯: {', '.join(search_conditions['exclude_keywords'])}")
            if original_poster:
                condition_summary.append(f"ğŸ‘¤ å‘å¸–äºº: {original_poster.display_name}")
            if exclude_op:
                condition_summary.append(f"ğŸš· æ’é™¤å‘å¸–äºº: {exclude_op.display_name}")
            if start_datetime:
                condition_summary.append(f"ğŸ“… èµ·å§‹æ—¥æœŸ: {start_datetime.strftime('%Y-%m-%d')}")
            if end_datetime:
                condition_summary.append(f"ğŸ“… ç»“æŸæ—¥æœŸ: {end_datetime.strftime('%Y-%m-%d')}")
            if min_reactions is not None:
                condition_summary.append(f"ğŸ‘ æœ€ä½ååº”æ•°: {min_reactions}")
            if min_replies is not None:
                condition_summary.append(f"ğŸ’¬ æœ€ä½å›å¤æ•°: {min_replies}")

            conditions_text = "\n".join(condition_summary) if condition_summary else "æ— ç‰¹å®šæœç´¢æ¡ä»¶"

            # Create cancel button for progress message
            cancel_button = discord.ui.Button(label="å–æ¶ˆæœç´¢", style=discord.ButtonStyle.danger)

            async def cancel_callback(btn_interaction):
                if search_id in self._active_searches:
                    self._active_searches[search_id]["cancel_event"].set()
                    await btn_interaction.response.send_message("æœç´¢å·²å–æ¶ˆ", ephemeral=True)

            cancel_button.callback = cancel_callback
            cancel_view = discord.ui.View(timeout=300)
            cancel_view.add_item(cancel_button)

            # Send initial progress message
            progress_message = await interaction.followup.send(
                embed=self.embed_builder.create_info_embed(
                    "æœç´¢è¿›è¡Œä¸­",
                    f"ğŸ“‹ æœç´¢æ¡ä»¶:\n{conditions_text}\n\nğŸ’« æ­£åœ¨æœç´¢æ´»åŠ¨å¸–å­..."
                ),
                view=cancel_view,
                ephemeral=True
            )

            filtered_results = []
            processed_count = 0
            start_time = datetime.now()

            # Process active threads
            active_threads = forum_channel.threads
            active_count = len(active_threads)

            if active_count > 0:
                try:
                    active_results = await self._process_thread_batch(active_threads, search_conditions, cancel_event)
                    if active_results:
                        filtered_results.extend(active_results)
                    processed_count += active_count

                    # Update progress
                    elapsed_time = (datetime.now() - start_time).total_seconds()
                    await progress_message.edit(
                        embed=self.embed_builder.create_info_embed(
                            "æœç´¢è¿›è¡Œä¸­",
                            f"âœ“ å·²å¤„ç†æ´»åŠ¨å¸–å­: {processed_count} ä¸ª\n"
                            f"ğŸ“Š åŒ¹é…ç»“æœ: {len(filtered_results)} ä¸ª\n"
                            f"â±ï¸ ç”¨æ—¶: {elapsed_time:.1f} ç§’\n"
                            f"â³ æ­£åœ¨æœç´¢å­˜æ¡£å¸–å­..."
                        )
                    )
                except Exception as e:
                    self._logger.error(f"Error processing active threads: {e}")
                    await progress_message.edit(
                        embed=self.embed_builder.create_warning_embed(
                            "æœç´¢è¿›è¡Œä¸­",
                            f"âŒ å¤„ç†æ´»åŠ¨å¸–å­æ—¶å‡ºç°é”™è¯¯\n"
                            f"ğŸ“Š å½“å‰ç»“æœ: {len(filtered_results)} ä¸ª\n"
                            f"â³ ç»§ç»­æœç´¢å­˜æ¡£å¸–å­..."
                        )
                    )

            # Process archived threads
            if not cancel_event.is_set():
                try:
                    archived_results = await self._search_archived_threads(
                        forum_channel,
                        search_conditions,
                        progress_message,
                        search_id,
                        max_results=settings.search.max_messages_per_search - len(filtered_results),
                        total_active=processed_count
                    )

                    if archived_results:
                        filtered_results.extend(archived_results)
                except Exception as e:
                    self._logger.error(f"Error searching archived threads: {e}")

            # Calculate total search time
            total_time = (datetime.now() - start_time).total_seconds()

            # Check if search was cancelled
            if cancel_event.is_set():
                if search_id in self._active_searches:
                    del self._active_searches[search_id]
                return

            # Update final progress status
            await progress_message.edit(
                embed=self.embed_builder.create_info_embed(
                    "æœç´¢å®Œæˆ",
                    f"ğŸ“‹ æœç´¢æ¡ä»¶:\n{conditions_text}\n\n"
                    f"âœ… å…±å¤„ç† {processed_count} ä¸ªå¸–å­\n"
                    f"ğŸ“Š æ‰¾åˆ° {len(filtered_results)} ä¸ªåŒ¹é…ç»“æœ\n"
                    f"â±ï¸ æ€»ç”¨æ—¶: {total_time:.1f} ç§’\n"
                    f"ğŸ’« æ­£åœ¨ç”Ÿæˆç»“æœé¡µé¢..."
                ),
                view=None
            )

            # Store search in history
            self._store_search_history(interaction.user.id, {
                'forum': forum_channel.name,
                'conditions': search_conditions,
                'results_count': len(filtered_results),
                'processed_count': processed_count,
                'duration': total_time
            })

            # Sort results based on selected order
            if order in self._sort_functions:
                sort_key, reverse = self._sort_functions[order]
                filtered_results.sort(key=sort_key, reverse=reverse)
            else:
                # Default sort by newest first
                sort_key, reverse = self._sort_functions["å‘å¸–æ—¶é—´ç”±æ–°åˆ°æ—§"]
                filtered_results.sort(key=sort_key, reverse=reverse)

            # Clean up active search
            if search_id in self._active_searches:
                del self._active_searches[search_id]

            if not filtered_results:
                await interaction.followup.send(
                    embed=self.embed_builder.create_warning_embed("æ— æœç´¢ç»“æœ", "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¸–å­"),
                    ephemeral=True
                )
                return

            # Create paginated display
            async def generate_embeds(page_items, page_number):
                """Generate embeds for result pages"""
                embeds = []
                for item in page_items:
                    thread = item['thread']
                    stats = item['stats']
                    first_message = item['first_message']

                    embed = discord.Embed(
                        title=truncate_text(thread.name, 256),
                        url=thread.jump_url,
                        color=EMBED_COLOR
                    )

                    if thread.owner:
                        embed.set_author(
                            name=thread.owner.display_name,
                            icon_url=thread.owner.display_avatar.url
                        )

                    if first_message and first_message.content:
                        # Highlight search keywords in content
                        summary = truncate_text(first_message.content.strip(), 1000)
                        embed.description = f"**å¸–å­æ‘˜è¦:**\n{summary}"

                        # Add thumbnail from first image in message if available
                        thumbnail_url = self.attachment_processor.get_first_image(first_message)
                        if thumbnail_url:
                            embed.set_thumbnail(url=thumbnail_url)

                    if thread.applied_tags:
                        tag_names = [tag.name for tag in thread.applied_tags]
                        embed.add_field(name="æ ‡ç­¾", value=", ".join(tag_names), inline=True)

                    # Add statistics
                    reaction_count = stats.get('reaction_count', 0) or 0
                    reply_count = stats.get('reply_count', 0) or 0
                    embed.add_field(
                        name="ç»Ÿè®¡",
                        value=f"ğŸ‘ {reaction_count} | ğŸ’¬ {reply_count}",
                        inline=True
                    )

                    # Add timestamps
                    embed.add_field(
                        name="æ—¶é—´",
                        value=f"åˆ›å»º: {discord.utils.format_dt(thread.created_at, 'R')}\n"
                              f"æœ€åæ´»è·ƒ: {discord.utils.format_dt(thread.last_message.created_at if thread.last_message else thread.created_at, 'R')}",
                        inline=True
                    )

                    # Add pagination info in footer
                    total_items = len(filtered_results)
                    start_idx = page_number * settings.search.messages_per_page + 1
                    end_idx = min((page_number + 1) * settings.search.messages_per_page, total_items)
                    embed.set_footer(text=f"ç¬¬ {start_idx}-{end_idx} ä¸ªç»“æœï¼Œå…± {total_items} ä¸ª")

                    embeds.append(embed)
                return embeds

            # Use existing pagination view
            paginator = MultiEmbedPaginationView(
                items=filtered_results,
                items_per_page=settings.search.messages_per_page,
                generate_embeds=generate_embeds
            )

            # Generate and send initial page embeds
            initial_page_items = paginator.get_page_items(0)
            if initial_page_items:
                initial_embeds = await generate_embeds(initial_page_items, 0)
                if initial_embeds:
                    await paginator.start(interaction, initial_embeds)
                else:
                    await interaction.followup.send(
                        embed=self.embed_builder.create_error_embed("é”™è¯¯", "æ— æ³•ç”Ÿæˆæœç´¢ç»“æœé¡µé¢"),
                        ephemeral=True
                    )
            else:
                await interaction.followup.send(
                    embed=self.embed_builder.create_warning_embed("æ— æœç´¢ç»“æœ", "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¸–å­"),
                    ephemeral=True
                )

        except Exception as e:
            self._logger.error(f"Search command error: {str(e)}", exc_info=True)
            await interaction.followup.send(
                embed=self.embed_builder.create_error_embed("æœç´¢é”™è¯¯", f"æœç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\nè¯·ç¨åé‡è¯•"),
                ephemeral=True
            )

    @forum_search.autocomplete('forum_name')
    async def forum_name_autocomplete(
        self,
        interaction: discord.Interaction,
        current: str,
    ) -> List[app_commands.Choice[str]]:
        """Enhanced forum name autocomplete with history prioritization"""
        try:
            if not interaction.guild:
                return []

            choices = []
            user_id = interaction.user.id

            # Get forums from user's search history first
            recent_forums = set()
            if user_id in self._search_history:
                for search in self._search_history[user_id]:
                    if 'forum' in search and search['forum']:
                        recent_forums.add(search['forum'])

            # Get all forum channels
            forum_channels = []
            for channel in interaction.guild.channels:
                if isinstance(channel, discord.ForumChannel):
                    # Skip if doesn't match current input
                    if current and current.lower() not in channel.name.lower():
                        continue

                    if channel.name and channel.id:
                        # Prioritize recently used forums
                        is_recent = channel.name in recent_forums
                        forum_channels.append((channel, is_recent))

            # Sort by recency (recent first) then alphabetically
            forum_channels.sort(key=lambda x: (not x[1], x[0].name.lower()))

            # Create choices
            choices = [
                app_commands.Choice(
                    name=f"#{channel.name}" + (" (æœ€è¿‘)" if is_recent else ""),
                    value=str(channel.id)
                )
                for channel, is_recent in forum_channels[:25]
            ]

            return choices

        except Exception as e:
            self._logger.error(f"Forum name autocomplete error: {str(e)}", exc_info=True)
            return []

    @forum_search.autocomplete('tag1')
    @forum_search.autocomplete('tag2')
    @forum_search.autocomplete('tag3')
    @forum_search.autocomplete('exclude_tag1')
    @forum_search.autocomplete('exclude_tag2')
    async def tag_autocomplete(
        self,
        interaction: discord.Interaction,
        current: str,
    ) -> List[app_commands.Choice[str]]:
        """Enhanced tag autocomplete with history prioritization"""
        try:
            if not interaction.guild:
                return []

            # Get selected forum ID
            forum_name = None
            for option in interaction.data.get("options", []):
                if option["name"] == "forum_name":
                    forum_name = option["value"]
                    break

            if not forum_name:
                return []

            # Get forum channel
            forum_channel = interaction.guild.get_channel(int(forum_name))
            if not isinstance(forum_channel, discord.ForumChannel):
                return []

            # Get all available tags
            available_tags = forum_channel.available_tags

            # Get currently selected tags in the command
            selected_tags = set()
            for option in interaction.data.get("options", []):
                if option["name"].startswith("tag") and option.get("value"):
                    selected_tags.add(option["value"])
                if option["name"].startswith("exclude_tag") and option.get("value"):
                    selected_tags.add(option["value"])

            # Get user's frequently used tags from history
            user_id = interaction.user.id
            tag_frequency = {}
            if user_id in self._search_history:
                for search in self._search_history[user_id]:
                    if 'conditions' in search and 'search_tags' in search['conditions']:
                        for tag in search['conditions']['search_tags']:
                            tag_frequency[tag] = tag_frequency.get(tag, 0) + 1

            # Filter and prioritize tags
            filtered_tags = []
            for tag in available_tags:
                # Skip already selected tags
                if tag.name in selected_tags:
                    continue

                # Skip tags that don't match current input
                if current and current.lower() not in tag.name.lower():
                    continue

                # Skip moderated tags for non-moderators
                if tag.moderated and not interaction.user.guild_permissions.manage_threads:
                    continue

                # Calculate priority (frequency of use)
                frequency = tag_frequency.get(tag.name.lower(), 0)
                filtered_tags.append((tag, frequency))

            # Sort tags by frequency (most used first) then alphabetically
            filtered_tags.sort(key=lambda x: (-x[1], x[0].name.lower()))

            # Create choices
            choices = [
                app_commands.Choice(
                    name=tag.name + (" ğŸ”„" if freq > 0 else ""),  # Indicator for frequently used tags
                    value=tag.name
                )
                for tag, freq in filtered_tags[:25]
            ]

            return choices

        except Exception as e:
            self._logger.error(f"Tag autocomplete error: {str(e)}", exc_info=True)
            return []

    @app_commands.command(name="search_history", description="æŸ¥çœ‹ä½ çš„æœç´¢å†å²")
    @app_commands.guild_only()
    async def search_history(self, interaction: discord.Interaction):
        """Display user's search history"""
        try:
            user_id = interaction.user.id

            if user_id not in self._search_history or not self._search_history[user_id]:
                await interaction.response.send_message(
                    embed=self.embed_builder.create_info_embed("æœç´¢å†å²", "ä½ è¿˜æ²¡æœ‰è¿›è¡Œè¿‡æœç´¢"),
                    ephemeral=True
                )
                return

            # Create embed with search history
            embed = discord.Embed(
                title="ä½ çš„æœç´¢å†å²",
                description="ä»¥ä¸‹æ˜¯ä½ æœ€è¿‘çš„æœç´¢è®°å½•",
                color=EMBED_COLOR
            )

            for i, search in enumerate(self._search_history[user_id][:5], 1):
                forum_name = search.get('forum', 'æœªçŸ¥è®ºå›')
                timestamp = search.get('timestamp', datetime.now())
                results_count = search.get('results_count', 0)
                duration = search.get('duration', 0)

                # Build conditions summary
                conditions = search.get('conditions', {})
                condition_parts = []

                if conditions.get('search_tags'):
                    condition_parts.append(f"æ ‡ç­¾: {', '.join(conditions['search_tags'][:2])}" +
                                         ("..." if len(conditions['search_tags']) > 2 else ""))

                if conditions.get('search_query'):
                    condition_parts.append(f"å…³é”®è¯: {conditions['search_query']}")

                if conditions.get('original_poster'):
                    condition_parts.append(f"å‘å¸–äºº: {conditions['original_poster'].display_name}")

                conditions_text = " | ".join(condition_parts) if condition_parts else "æ— ç‰¹å®šæ¡ä»¶"

                embed.add_field(
                    name=f"{i}. {forum_name} ({discord.utils.format_dt(timestamp, 'R')})",
                    value=f"æ¡ä»¶: {conditions_text}\nç»“æœ: {results_count} ä¸ª | ç”¨æ—¶: {duration:.1f} ç§’",
                    inline=False
                )

            await interaction.response.send_message(embed=embed, ephemeral=True)

        except Exception as e:
            self._logger.error(f"Search history command error: {str(e)}", exc_info=True)
            await interaction.response.send_message(
                embed=self.embed_builder.create_error_embed("é”™è¯¯", "è·å–æœç´¢å†å²å¤±è´¥"),
                ephemeral=True
            )

async def setup(bot: commands.Bot):
    await bot.add_cog(Search(bot))