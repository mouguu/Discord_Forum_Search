#!/usr/bin/env python3
"""
ç¼“å­˜æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ç¼“å­˜ç³»ç»Ÿçš„æ€§èƒ½å’Œæ•…éšœè½¬ç§»æœºåˆ¶
"""
import sys
import asyncio
import time
import random
import statistics
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utils.cache_manager import cache_manager
from config.settings import settings

class CachePerformanceTester:
    """ç¼“å­˜æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = {}
        
    async def test_cache_hit_rate(self, num_operations=1000):
        """æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡"""
        print(f"ğŸ¯ æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡ ({num_operations} æ¬¡æ“ä½œ)...")
        
        # åˆå§‹åŒ–ç¼“å­˜
        cache_manager.initialize(
            use_redis=settings.cache.use_redis,
            redis_url=settings.cache.redis_url,
            cache_ttl=settings.cache.ttl,
            thread_cache_size=settings.cache.thread_cache_size
        )
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_keys = [f"test_key_{i}" for i in range(100)]
        test_data = {key: f"test_data_{i}" for i, key in enumerate(test_keys)}
        
        # å†™å…¥æµ‹è¯•æ•°æ®
        start_time = time.time()
        for key, value in test_data.items():
            await cache_manager.general_cache.set(key, value)
        write_time = time.time() - start_time
        
        # æ‰§è¡Œè¯»å–æ“ä½œï¼ˆ80%å‘½ä¸­ï¼Œ20%æœªå‘½ä¸­ï¼‰
        hits = 0
        misses = 0
        read_times = []
        
        for _ in range(num_operations):
            # 80%æ¦‚ç‡é€‰æ‹©å­˜åœ¨çš„keyï¼Œ20%æ¦‚ç‡é€‰æ‹©ä¸å­˜åœ¨çš„key
            if random.random() < 0.8:
                key = random.choice(test_keys)
                expected_hit = True
            else:
                key = f"nonexistent_key_{random.randint(1000, 9999)}"
                expected_hit = False
            
            start_read = time.time()
            result = await cache_manager.general_cache.get(key)
            read_time = time.time() - start_read
            read_times.append(read_time)
            
            if result is not None:
                hits += 1
            else:
                misses += 1
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        hit_rate = (hits / num_operations) * 100
        avg_read_time = statistics.mean(read_times)
        median_read_time = statistics.median(read_times)
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = cache_manager.get_stats()
        
        self.test_results['cache_hit_rate'] = {
            'num_operations': num_operations,
            'hits': hits,
            'misses': misses,
            'hit_rate_percent': hit_rate,
            'write_time_seconds': write_time,
            'avg_read_time_ms': avg_read_time * 1000,
            'median_read_time_ms': median_read_time * 1000,
            'cache_stats': cache_stats
        }
        
        print(f"  âœ… å‘½ä¸­ç‡: {hit_rate:.1f}% ({hits}/{num_operations})")
        print(f"  âœ… å¹³å‡è¯»å–æ—¶é—´: {avg_read_time * 1000:.2f}ms")
        print(f"  âœ… ä¸­ä½æ•°è¯»å–æ—¶é—´: {median_read_time * 1000:.2f}ms")
        print(f"  âœ… å†™å…¥æ—¶é—´: {write_time:.2f}ç§’")
        
        # éªŒè¯å‘½ä¸­ç‡ç›®æ ‡ï¼ˆåº”è¯¥æ¥è¿‘80%ï¼‰
        expected_hit_rate = 80.0
        tolerance = 5.0  # 5%å®¹å·®
        
        if abs(hit_rate - expected_hit_rate) <= tolerance:
            print(f"  âœ… å‘½ä¸­ç‡ç¬¦åˆé¢„æœŸ (ç›®æ ‡: {expected_hit_rate}% Â± {tolerance}%)")
            return True
        else:
            print(f"  âš ï¸ å‘½ä¸­ç‡åç¦»é¢„æœŸ (ç›®æ ‡: {expected_hit_rate}% Â± {tolerance}%, å®é™…: {hit_rate:.1f}%)")
            return False
    
    async def test_cache_performance_comparison(self):
        """æµ‹è¯•å¯ç”¨/ç¦ç”¨ç¼“å­˜çš„æ€§èƒ½å¯¹æ¯”"""
        print("âš¡ æµ‹è¯•ç¼“å­˜æ€§èƒ½å¯¹æ¯”...")
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_data = {f"perf_key_{i}": f"performance_test_data_{i}" * 10 for i in range(50)}
        num_reads = 200
        
        # æµ‹è¯•1: å¯ç”¨ç¼“å­˜
        print("  ğŸ“Š æµ‹è¯•å¯ç”¨ç¼“å­˜çš„æ€§èƒ½...")
        cache_manager.initialize(use_redis=settings.cache.use_redis)
        
        # é¢„çƒ­ç¼“å­˜
        for key, value in test_data.items():
            await cache_manager.general_cache.set(key, value)
        
        # æµ‹è¯•è¯»å–æ€§èƒ½
        start_time = time.time()
        for _ in range(num_reads):
            key = random.choice(list(test_data.keys()))
            await cache_manager.general_cache.get(key)
        cached_time = time.time() - start_time
        
        # æµ‹è¯•2: æ¨¡æ‹Ÿæ— ç¼“å­˜ï¼ˆæ¯æ¬¡éƒ½æœªå‘½ä¸­ï¼‰
        print("  ğŸ“Š æµ‹è¯•æ— ç¼“å­˜çš„æ€§èƒ½...")
        start_time = time.time()
        for _ in range(num_reads):
            # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢å»¶è¿Ÿ
            await asyncio.sleep(0.001)  # 1mså»¶è¿Ÿæ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        uncached_time = time.time() - start_time
        
        # è®¡ç®—æ€§èƒ½æå‡
        performance_improvement = ((uncached_time - cached_time) / uncached_time) * 100
        
        self.test_results['cache_performance_comparison'] = {
            'num_reads': num_reads,
            'cached_time_seconds': cached_time,
            'uncached_time_seconds': uncached_time,
            'performance_improvement_percent': performance_improvement,
            'speedup_factor': uncached_time / cached_time if cached_time > 0 else 0
        }
        
        print(f"  âœ… å¯ç”¨ç¼“å­˜æ—¶é—´: {cached_time:.3f}ç§’")
        print(f"  âœ… æ— ç¼“å­˜æ—¶é—´: {uncached_time:.3f}ç§’")
        print(f"  âœ… æ€§èƒ½æå‡: {performance_improvement:.1f}%")
        print(f"  âœ… åŠ é€Ÿå€æ•°: {uncached_time / cached_time:.1f}x")
        
        # éªŒè¯æ€§èƒ½æå‡ç›®æ ‡ï¼ˆåº”è¯¥æœ‰æ˜¾è‘—æå‡ï¼‰
        min_improvement = 30.0  # è‡³å°‘30%æå‡
        
        if performance_improvement >= min_improvement:
            print(f"  âœ… æ€§èƒ½æå‡ç¬¦åˆé¢„æœŸ (ç›®æ ‡: â‰¥{min_improvement}%)")
            return True
        else:
            print(f"  âš ï¸ æ€§èƒ½æå‡ä½äºé¢„æœŸ (ç›®æ ‡: â‰¥{min_improvement}%, å®é™…: {performance_improvement:.1f}%)")
            return False
    
    async def test_redis_failover(self):
        """æµ‹è¯•Redisæ•…éšœè½¬ç§»æœºåˆ¶"""
        print("ğŸ”„ æµ‹è¯•Redisæ•…éšœè½¬ç§»æœºåˆ¶...")
        
        if not settings.cache.use_redis:
            print("  âš ï¸ Redisæœªå¯ç”¨ï¼Œè·³è¿‡æ•…éšœè½¬ç§»æµ‹è¯•")
            self.test_results['redis_failover'] = {
                'status': 'skipped',
                'reason': 'Redis not enabled'
            }
            return True
        
        try:
            # åˆå§‹åŒ–ç¼“å­˜ï¼ˆå¯ç”¨Redisï¼‰
            cache_manager.initialize(
                use_redis=True,
                redis_url=settings.cache.redis_url
            )
            
            # æµ‹è¯•æ­£å¸¸Redisæ“ä½œ
            test_key = "failover_test"
            test_value = "failover_test_value"
            
            await cache_manager.general_cache.set(test_key, test_value)
            result = await cache_manager.general_cache.get(test_key)
            
            redis_working = result == test_value
            print(f"  ğŸ“Š Redisæ­£å¸¸å·¥ä½œ: {'æ˜¯' if redis_working else 'å¦'}")
            
            # æ¨¡æ‹ŸRedisæ•…éšœï¼ˆé€šè¿‡ä½¿ç”¨é”™è¯¯çš„URLï¼‰
            print("  ğŸ”§ æ¨¡æ‹ŸRedisè¿æ¥æ•…éšœ...")
            cache_manager.initialize(
                use_redis=True,
                redis_url="redis://invalid_host:6379/0"  # æ— æ•ˆçš„Redis URL
            )
            
            # æµ‹è¯•æ•…éšœè½¬ç§»åˆ°å†…å­˜ç¼“å­˜
            fallback_key = "fallback_test"
            fallback_value = "fallback_test_value"
            
            start_time = time.time()
            await cache_manager.general_cache.set(fallback_key, fallback_value)
            result = await cache_manager.general_cache.get(fallback_key)
            fallback_time = time.time() - start_time
            
            fallback_working = result == fallback_value
            print(f"  ğŸ“Š å†…å­˜ç¼“å­˜æ•…éšœè½¬ç§»: {'æˆåŠŸ' if fallback_working else 'å¤±è´¥'}")
            print(f"  ğŸ“Š æ•…éšœè½¬ç§»æ—¶é—´: {fallback_time * 1000:.2f}ms")
            
            self.test_results['redis_failover'] = {
                'redis_initially_working': redis_working,
                'fallback_working': fallback_working,
                'fallback_time_ms': fallback_time * 1000,
                'status': 'passed' if fallback_working else 'failed'
            }
            
            return fallback_working
            
        except Exception as e:
            print(f"  âŒ æ•…éšœè½¬ç§»æµ‹è¯•å‡ºé”™: {e}")
            self.test_results['redis_failover'] = {
                'status': 'failed',
                'error': str(e)
            }
            return False
    
    async def test_cache_memory_usage(self):
        """æµ‹è¯•ç¼“å­˜å†…å­˜ä½¿ç”¨"""
        print("ğŸ’¾ æµ‹è¯•ç¼“å­˜å†…å­˜ä½¿ç”¨...")
        
        # åˆå§‹åŒ–ç¼“å­˜
        cache_manager.initialize()
        
        # è·å–åˆå§‹å†…å­˜ä½¿ç”¨
        import psutil
        process = psutil.Process()
        initial_memory = process.memory_info().rss
        
        # å†™å…¥å¤§é‡æ•°æ®
        large_data = "x" * 1024  # 1KBæ•°æ®
        num_items = 1000
        
        start_time = time.time()
        for i in range(num_items):
            await cache_manager.general_cache.set(f"memory_test_{i}", large_data)
        write_time = time.time() - start_time
        
        # è·å–å†™å…¥åå†…å­˜ä½¿ç”¨
        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = cache_manager.get_stats()
        
        self.test_results['cache_memory_usage'] = {
            'num_items': num_items,
            'item_size_bytes': len(large_data),
            'total_data_size_kb': (num_items * len(large_data)) / 1024,
            'initial_memory_mb': initial_memory / (1024 * 1024),
            'final_memory_mb': final_memory / (1024 * 1024),
            'memory_increase_mb': memory_increase / (1024 * 1024),
            'write_time_seconds': write_time,
            'cache_stats': cache_stats
        }
        
        print(f"  âœ… å†™å…¥é¡¹ç›®æ•°: {num_items}")
        print(f"  âœ… å•é¡¹å¤§å°: {len(large_data)} å­—èŠ‚")
        print(f"  âœ… æ€»æ•°æ®å¤§å°: {(num_items * len(large_data)) / 1024:.1f} KB")
        print(f"  âœ… å†…å­˜å¢é•¿: {memory_increase / (1024 * 1024):.1f} MB")
        print(f"  âœ… å†™å…¥æ—¶é—´: {write_time:.2f}ç§’")
        
        return True

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("âš¡ å¼€å§‹ç¼“å­˜æ€§èƒ½æµ‹è¯•...")
    print("=" * 50)
    
    tester = CachePerformanceTester()
    results = []
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        results.append(await tester.test_cache_hit_rate())
        results.append(await tester.test_cache_performance_comparison())
        results.append(await tester.test_redis_failover())
        results.append(await tester.test_cache_memory_usage())
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        import json
        report_path = project_root / "logs" / "cache_performance_report.json"
        report_path.parent.mkdir(exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'test_results': tester.test_results,
                'summary': {
                    'total_tests': len(results),
                    'passed': sum(results),
                    'failed': len(results) - sum(results)
                }
            }, f, indent=2, ensure_ascii=False)
        
        print("=" * 50)
        print("ğŸ“Š ç¼“å­˜æ€§èƒ½æµ‹è¯•æ‘˜è¦:")
        print(f"  æ€»æµ‹è¯•æ•°: {len(results)}")
        print(f"  é€šè¿‡: {sum(results)}")
        print(f"  å¤±è´¥: {len(results) - sum(results)}")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
        
        if all(results):
            print("ğŸ‰ æ‰€æœ‰ç¼“å­˜æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")
            return True
        else:
            print("âŒ éƒ¨åˆ†ç¼“å­˜æ€§èƒ½æµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ ç¼“å­˜æ€§èƒ½æµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
