#!/usr/bin/env python3
"""
åŸºç¡€ç›‘æ§ç³»ç»Ÿæµ‹è¯•è„šæœ¬
ä¸ä¾èµ–å¤–éƒ¨æ¨¡å—çš„ç›‘æ§åŠŸèƒ½éªŒè¯
"""
import sys
import os
import time
import json
import platform
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from config.settings import settings

class BasicMonitoringTester:
    """åŸºç¡€ç›‘æ§ç³»ç»Ÿæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = {}
        
    def test_config_monitoring(self):
        """æµ‹è¯•é…ç½®ç›‘æ§åŠŸèƒ½"""
        print("ğŸ”§ æµ‹è¯•é…ç½®ç›‘æ§åŠŸèƒ½...")
        
        # æµ‹è¯•é…ç½®åŠ è½½
        config_tests = {
            'bot_config': {
                'command_prefix': settings.bot.command_prefix,
                'log_level': settings.bot.log_level,
                'embed_color': settings.bot.embed_color
            },
            'search_config': {
                'max_messages_per_search': settings.search.max_messages_per_search,
                'messages_per_page': settings.search.messages_per_page,
                'concurrent_limit': settings.search.concurrent_limit
            },
            'cache_config': {
                'use_redis': settings.cache.use_redis,
                'ttl': settings.cache.ttl,
                'thread_cache_size': settings.cache.thread_cache_size
            }
        }
        
        # éªŒè¯é…ç½®å€¼
        errors = []
        
        # Boté…ç½®éªŒè¯
        if not isinstance(settings.bot.command_prefix, str):
            errors.append("å‘½ä»¤å‰ç¼€åº”ä¸ºå­—ç¬¦ä¸²")
        if settings.bot.log_level not in ["DEBUG", "INFO", "WARNING", "ERROR"]:
            errors.append(f"æ— æ•ˆçš„æ—¥å¿—çº§åˆ«: {settings.bot.log_level}")
        if not isinstance(settings.bot.embed_color, int):
            errors.append("åµŒå…¥é¢œè‰²åº”ä¸ºæ•´æ•°")
            
        # æœç´¢é…ç½®éªŒè¯
        if settings.search.max_messages_per_search <= 0:
            errors.append("æœ€å¤§æœç´¢æ¶ˆæ¯æ•°åº”å¤§äº0")
        if settings.search.messages_per_page <= 0:
            errors.append("æ¯é¡µæ¶ˆæ¯æ•°åº”å¤§äº0")
        if settings.search.concurrent_limit <= 0:
            errors.append("å¹¶å‘é™åˆ¶åº”å¤§äº0")
            
        # ç¼“å­˜é…ç½®éªŒè¯
        if not isinstance(settings.cache.use_redis, bool):
            errors.append("Redisä½¿ç”¨æ ‡å¿—åº”ä¸ºå¸ƒå°”å€¼")
        if settings.cache.ttl <= 0:
            errors.append("ç¼“å­˜TTLåº”å¤§äº0")
            
        self.test_results['config_monitoring'] = {
            'status': 'passed' if not errors else 'failed',
            'config_values': config_tests,
            'errors': errors
        }
        
        if not errors:
            print("  âœ… é…ç½®ç›‘æ§æµ‹è¯•é€šè¿‡")
            print(f"    - å‘½ä»¤å‰ç¼€: {settings.bot.command_prefix}")
            print(f"    - æ—¥å¿—çº§åˆ«: {settings.bot.log_level}")
            print(f"    - æœ€å¤§æœç´¢æ¶ˆæ¯æ•°: {settings.search.max_messages_per_search}")
            print(f"    - å¹¶å‘é™åˆ¶: {settings.search.concurrent_limit}")
        else:
            print("  âŒ é…ç½®ç›‘æ§æµ‹è¯•å¤±è´¥:")
            for error in errors:
                print(f"    - {error}")
                
        return len(errors) == 0
    
    def test_file_system_monitoring(self):
        """æµ‹è¯•æ–‡ä»¶ç³»ç»Ÿç›‘æ§åŠŸèƒ½"""
        print("ğŸ“ æµ‹è¯•æ–‡ä»¶ç³»ç»Ÿç›‘æ§åŠŸèƒ½...")
        
        # æ£€æŸ¥å…³é”®ç›®å½•å’Œæ–‡ä»¶
        critical_paths = [
            'config/settings.py',
            'utils/',
            'cogs/',
            'main.py'
        ]
        
        missing_paths = []
        existing_paths = []
        
        for path in critical_paths:
            full_path = project_root / path
            if full_path.exists():
                existing_paths.append(path)
            else:
                missing_paths.append(path)
        
        # æ£€æŸ¥æ—¥å¿—ç›®å½•
        logs_dir = project_root / "logs"
        logs_dir.mkdir(exist_ok=True)
        
        # æµ‹è¯•æ–‡ä»¶å†™å…¥æƒé™
        test_file = logs_dir / "monitoring_test.tmp"
        write_permission = True
        try:
            with open(test_file, 'w') as f:
                f.write("test")
            test_file.unlink()  # åˆ é™¤æµ‹è¯•æ–‡ä»¶
        except Exception as e:
            write_permission = False
            
        self.test_results['file_system_monitoring'] = {
            'status': 'passed' if not missing_paths and write_permission else 'failed',
            'existing_paths': existing_paths,
            'missing_paths': missing_paths,
            'write_permission': write_permission
        }
        
        print(f"  âœ… å­˜åœ¨çš„å…³é”®è·¯å¾„: {len(existing_paths)}/{len(critical_paths)}")
        print(f"  âœ… æ—¥å¿—ç›®å½•å†™å…¥æƒé™: {'æ˜¯' if write_permission else 'å¦'}")
        
        if missing_paths:
            print(f"  âš ï¸ ç¼ºå¤±çš„è·¯å¾„: {missing_paths}")
            
        return len(missing_paths) == 0 and write_permission
    
    def test_system_info_collection(self):
        """æµ‹è¯•ç³»ç»Ÿä¿¡æ¯æ”¶é›†"""
        print("ğŸ’» æµ‹è¯•ç³»ç»Ÿä¿¡æ¯æ”¶é›†...")
        
        # æ”¶é›†åŸºç¡€ç³»ç»Ÿä¿¡æ¯
        system_info = {
            'platform': platform.system(),
            'platform_release': platform.release(),
            'platform_version': platform.version(),
            'architecture': platform.machine(),
            'processor': platform.processor(),
            'python_version': platform.python_version(),
            'python_implementation': platform.python_implementation()
        }
        
        # æ”¶é›†è¿›ç¨‹ä¿¡æ¯
        process_info = {
            'pid': os.getpid(),
            'working_directory': os.getcwd(),
            'environment_variables': len(os.environ)
        }
        
        # éªŒè¯ä¿¡æ¯æ”¶é›†
        required_fields = ['platform', 'python_version', 'pid']
        missing_fields = [field for field in required_fields if not system_info.get(field) and not process_info.get(field)]
        
        self.test_results['system_info_collection'] = {
            'status': 'passed' if not missing_fields else 'failed',
            'system_info': system_info,
            'process_info': process_info,
            'missing_fields': missing_fields
        }
        
        print(f"  âœ… æ“ä½œç³»ç»Ÿ: {system_info['platform']} {system_info['platform_release']}")
        print(f"  âœ… Pythonç‰ˆæœ¬: {system_info['python_version']}")
        print(f"  âœ… è¿›ç¨‹ID: {process_info['pid']}")
        print(f"  âœ… å·¥ä½œç›®å½•: {process_info['working_directory']}")
        
        return len(missing_fields) == 0
    
    def test_performance_baseline(self):
        """æµ‹è¯•æ€§èƒ½åŸºå‡†æ”¶é›†"""
        print("âš¡ æµ‹è¯•æ€§èƒ½åŸºå‡†æ”¶é›†...")
        
        # ç®€å•çš„æ€§èƒ½æµ‹è¯•
        performance_tests = {}
        
        # æµ‹è¯•1: å­—ç¬¦ä¸²æ“ä½œæ€§èƒ½
        start_time = time.time()
        test_string = "performance test " * 1000
        for _ in range(1000):
            test_string.upper().lower().strip()
        string_ops_time = time.time() - start_time
        
        # æµ‹è¯•2: åˆ—è¡¨æ“ä½œæ€§èƒ½
        start_time = time.time()
        test_list = list(range(10000))
        for _ in range(100):
            sorted(test_list, reverse=True)
        list_ops_time = time.time() - start_time
        
        # æµ‹è¯•3: å­—å…¸æ“ä½œæ€§èƒ½
        start_time = time.time()
        test_dict = {f"key_{i}": f"value_{i}" for i in range(1000)}
        for _ in range(1000):
            _ = test_dict.get(f"key_{500}")
        dict_ops_time = time.time() - start_time
        
        performance_tests = {
            'string_operations_ms': string_ops_time * 1000,
            'list_operations_ms': list_ops_time * 1000,
            'dict_operations_ms': dict_ops_time * 1000
        }
        
        # éªŒè¯æ€§èƒ½åŸºå‡†
        performance_ok = all(time_ms < 1000 for time_ms in performance_tests.values())  # æ‰€æœ‰æ“ä½œåº”åœ¨1ç§’å†…å®Œæˆ
        
        self.test_results['performance_baseline'] = {
            'status': 'passed' if performance_ok else 'failed',
            'performance_tests': performance_tests,
            'baseline_met': performance_ok
        }
        
        print(f"  âœ… å­—ç¬¦ä¸²æ“ä½œ: {performance_tests['string_operations_ms']:.2f}ms")
        print(f"  âœ… åˆ—è¡¨æ“ä½œ: {performance_tests['list_operations_ms']:.2f}ms")
        print(f"  âœ… å­—å…¸æ“ä½œ: {performance_tests['dict_operations_ms']:.2f}ms")
        
        return performance_ok
    
    def test_logging_functionality(self):
        """æµ‹è¯•æ—¥å¿—åŠŸèƒ½"""
        print("ğŸ“ æµ‹è¯•æ—¥å¿—åŠŸèƒ½...")
        
        import logging
        
        # åˆ›å»ºæµ‹è¯•æ—¥å¿—å™¨
        test_logger = logging.getLogger('monitoring_test')
        test_logger.setLevel(logging.INFO)
        
        # æµ‹è¯•æ—¥å¿—æ–‡ä»¶å†™å…¥
        logs_dir = project_root / "logs"
        logs_dir.mkdir(exist_ok=True)
        log_file = logs_dir / "monitoring_test.log"
        
        try:
            # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.FileHandler(log_file)
            file_handler.setLevel(logging.INFO)
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(formatter)
            test_logger.addHandler(file_handler)
            
            # å†™å…¥æµ‹è¯•æ—¥å¿—
            test_logger.info("ç›‘æ§æµ‹è¯•æ—¥å¿— - å¼€å§‹")
            test_logger.warning("ç›‘æ§æµ‹è¯•æ—¥å¿— - è­¦å‘Š")
            test_logger.error("ç›‘æ§æµ‹è¯•æ—¥å¿— - é”™è¯¯")
            
            # éªŒè¯æ—¥å¿—æ–‡ä»¶
            log_exists = log_file.exists()
            log_size = log_file.stat().st_size if log_exists else 0
            
            # æ¸…ç†
            file_handler.close()
            test_logger.removeHandler(file_handler)
            if log_file.exists():
                log_file.unlink()
                
            self.test_results['logging_functionality'] = {
                'status': 'passed' if log_exists and log_size > 0 else 'failed',
                'log_file_created': log_exists,
                'log_file_size': log_size
            }
            
            print(f"  âœ… æ—¥å¿—æ–‡ä»¶åˆ›å»º: {'æˆåŠŸ' if log_exists else 'å¤±è´¥'}")
            print(f"  âœ… æ—¥å¿—æ–‡ä»¶å¤§å°: {log_size} å­—èŠ‚")
            
            return log_exists and log_size > 0
            
        except Exception as e:
            self.test_results['logging_functionality'] = {
                'status': 'failed',
                'error': str(e)
            }
            print(f"  âŒ æ—¥å¿—æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”ŸæˆåŸºç¡€ç›‘æ§æµ‹è¯•æŠ¥å‘Š...")
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'test_results': self.test_results,
            'summary': {
                'total_tests': len(self.test_results),
                'passed': len([r for r in self.test_results.values() if r['status'] == 'passed']),
                'failed': len([r for r in self.test_results.values() if r['status'] == 'failed']),
                'skipped': len([r for r in self.test_results.values() if r['status'] == 'skipped'])
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        logs_dir = project_root / "logs"
        logs_dir.mkdir(exist_ok=True)
        report_path = logs_dir / "basic_monitoring_test_report.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return report

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” å¼€å§‹åŸºç¡€ç›‘æ§ç³»ç»Ÿæµ‹è¯•...")
    print("=" * 50)
    
    tester = BasicMonitoringTester()
    results = []
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        results.append(tester.test_config_monitoring())
        results.append(tester.test_file_system_monitoring())
        results.append(tester.test_system_info_collection())
        results.append(tester.test_performance_baseline())
        results.append(tester.test_logging_functionality())
        
        # ç”ŸæˆæŠ¥å‘Š
        report = tester.generate_report()
        
        print("=" * 50)
        print("ğŸ“Š åŸºç¡€ç›‘æ§æµ‹è¯•æ‘˜è¦:")
        print(f"  æ€»æµ‹è¯•æ•°: {report['summary']['total_tests']}")
        print(f"  é€šè¿‡: {report['summary']['passed']}")
        print(f"  å¤±è´¥: {report['summary']['failed']}")
        print(f"  è·³è¿‡: {report['summary']['skipped']}")
        
        if all(results):
            print("ğŸ‰ æ‰€æœ‰åŸºç¡€ç›‘æ§æµ‹è¯•é€šè¿‡ï¼")
            return True
        else:
            print("âŒ éƒ¨åˆ†åŸºç¡€ç›‘æ§æµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ åŸºç¡€ç›‘æ§æµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
